{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertClassifierCUB.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9yCMH9y0t90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e8cd8d85-39d6-492e-ec15-c140dff8cf1f"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGiPQZ1v1Z2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zze5WF-1dXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsT9hj5G1hEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "6eba2f8e-f374-46fc-cada-05f5d9102c67"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/CUB_captions.csv\", header=None, names=['Label',  'ID', 'Sentences'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,856\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>ID</th>\n",
              "      <th>Sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5884.0</th>\n",
              "      <td>017.Cardinal/Cardinal_0089_18005</td>\n",
              "      <td>140</td>\n",
              "      <td>a large round bird with red feathers, and a lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6497.0</th>\n",
              "      <td>018.Spotted_Catbird/Spotted_Catbird_0046_19399</td>\n",
              "      <td>151</td>\n",
              "      <td>dark green bird with a light yellow belly and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6561.0</th>\n",
              "      <td>018.Spotted_Catbird/Spotted_Catbird_0042_19430</td>\n",
              "      <td>152</td>\n",
              "      <td>this bird has a speckled breast with green spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5072.0</th>\n",
              "      <td>015.Lazuli_Bunting/Lazuli_Bunting_0087_15096</td>\n",
              "      <td>123</td>\n",
              "      <td>a beautiful small blue bird that is blue on it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1605.0</th>\n",
              "      <td>005.Crested_Auklet/Crested_Auklet_0040_794912</td>\n",
              "      <td>44</td>\n",
              "      <td>this bird is mostly black with a small head, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1481.0</th>\n",
              "      <td>005.Crested_Auklet/Crested_Auklet_0066_785251</td>\n",
              "      <td>41</td>\n",
              "      <td>the bird has a black eyering and an orange bil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6812.0</th>\n",
              "      <td>019.Gray_Catbird/Gray_Catbird_0134_20596</td>\n",
              "      <td>157</td>\n",
              "      <td>a small bird with dark spiky feathers, and a p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642.0</th>\n",
              "      <td>003.Sooty_Albatross/Sooty_Albatross_0043_1076</td>\n",
              "      <td>18</td>\n",
              "      <td>a very large bird with an extremely large bill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6494.0</th>\n",
              "      <td>018.Spotted_Catbird/Spotted_Catbird_0046_19399</td>\n",
              "      <td>151</td>\n",
              "      <td>this is a yellow and grey bird with a black ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016.0</th>\n",
              "      <td>011.Rusty_Blackbird/Rusty_Blackbird_0114_6760</td>\n",
              "      <td>73</td>\n",
              "      <td>this particular bird has a belly that is black...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Label  ...                                          Sentences\n",
              "5884.0                017.Cardinal/Cardinal_0089_18005  ...  a large round bird with red feathers, and a lo...\n",
              "6497.0  018.Spotted_Catbird/Spotted_Catbird_0046_19399  ...  dark green bird with a light yellow belly and ...\n",
              "6561.0  018.Spotted_Catbird/Spotted_Catbird_0042_19430  ...  this bird has a speckled breast with green spo...\n",
              "5072.0    015.Lazuli_Bunting/Lazuli_Bunting_0087_15096  ...  a beautiful small blue bird that is blue on it...\n",
              "1605.0   005.Crested_Auklet/Crested_Auklet_0040_794912  ...  this bird is mostly black with a small head, w...\n",
              "1481.0   005.Crested_Auklet/Crested_Auklet_0066_785251  ...  the bird has a black eyering and an orange bil...\n",
              "6812.0        019.Gray_Catbird/Gray_Catbird_0134_20596  ...  a small bird with dark spiky feathers, and a p...\n",
              "642.0    003.Sooty_Albatross/Sooty_Albatross_0043_1076  ...  a very large bird with an extremely large bill...\n",
              "6494.0  018.Spotted_Catbird/Spotted_Catbird_0046_19399  ...  this is a yellow and grey bird with a black ch...\n",
              "3016.0   011.Rusty_Blackbird/Rusty_Blackbird_0114_6760  ...  this particular bird has a belly that is black...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQNyxhKi1uvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "import numpy as np\n",
        "\n",
        "sentences = df.Sentences.values\n",
        "labels_text = df.Label.values\n",
        "labels = df.ID.values\n",
        "\n",
        "labels = np.delete(labels, 0)\n",
        "labels_text = np.delete(labels_text, 0)\n",
        "sentences = np.delete(sentences, 0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR47p1B_1vx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "78be042a-ed7c-455c-b081-029fe1769e00"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UllOFv2i13tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "22f7c324-486b-427a-faf4-56c807eba873"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  a bird with a very long wing span and a long pointed beak.\n",
            "Tokenized:  ['a', 'bird', 'with', 'a', 'very', 'long', 'wing', 'span', 'and', 'a', 'long', 'pointed', 'beak', '.']\n",
            "Token IDs:  [1037, 4743, 2007, 1037, 2200, 2146, 3358, 8487, 1998, 1037, 2146, 4197, 23525, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMEcsnbB16y_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9d2760cf-c666-41ea-e923-bc32938db3ae"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "    if  len(input_ids) == 80:\n",
        "      print('sent with max len :', sent)\n",
        "      print('number of words insent with max len :', len(sent.split()))\n",
        "      print('index of sent with max len :', np.where(sentences==sent))\n",
        "\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "\n",
        "atwal = []\n",
        "for i in sentences:\n",
        "  atwal.append(len(i.split()))\n",
        "atwal.sort(reverse=True)\n",
        "print('Max number of words in a sentnces length: ', atwal[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  70\n",
            "Max number of words in a sentnces length:  55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIMAgJhr2hsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "9f37343b-4fbe-478c-a049-f015be281fe3"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-853e47e6d93a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Print sentence 0, now as a list of IDs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt8EBjNs3d7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}