{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertAttn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mVHKOFJKObV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "ef40e2ee-23b0-4115-bb12-27a70ae56611"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 16 08:23:44 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39EBfvPKZkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer , BertModel\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():        \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/CUB_captions.csv\", header=None, names=['Label',  'ID', 'Sentences'])\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "sentences = df.Sentences.values\n",
        "sentences = np.delete(sentences, 0)\n",
        "\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "input_ids = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(sent, add_special_tokens = True, max_length = 18, pad_to_max_length = True, return_attention_mask = True,   \n",
        "                        return_tensors = 'pt', truncation=True)\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "segments_ids = []\n",
        "for i in range(input_ids.size()[0]):\n",
        "  segments_id = [1] * input_ids.size()[1]\n",
        "  segments_ids.append(segments_id)\n",
        "segments_ids = torch.tensor(segments_ids)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69LgKcw2VZMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "3afe0445-af8c-469a-e974-f580df43a1c0"
      },
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "!rm -r sample_data\n",
        "\n",
        "#clone repo AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git\n",
        "\n",
        "#Changing Working dirctory to data\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/\n",
        "\n",
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hbzc_P1FuxMkcabkgn9ZKinBwW683j45' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hbzc_P1FuxMkcabkgn9ZKinBwW683j45\" -O CUB_200_2011.tgz && rm -rf /tmp/cookies.txt\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz\n",
        "\n",
        "#Changing Working dirctory to code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 17.91 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "--2020-07-16 08:47:47--  https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.126.113, 108.177.126.100, 108.177.126.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.126.113|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWVbsFHKYN7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}